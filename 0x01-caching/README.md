0x01. Caching

Resources
Cache replacement policies - FIFO
Cache replacement policies - LIFO
Cache replacement policies - LRU
Cache replacement policies - MRU
Cache replacement policies - LFU
Learning Objectives
At the end of this project, you are expected to be able to explain to anyone, without the help of Google:

General
What a caching system is: A caching system is a mechanism used in computing to temporarily store data that is frequently accessed or computationally expensive to generate. The purpose is to improve performance by reducing the time it takes to access the data, typically by storing it in a faster, closer-to-access memory location.

What FIFO means: FIFO stands for "First-In, First-Out." It is a cache replacement policy where the oldest entry in the cache is removed first when the cache reaches its maximum capacity.

What LIFO means: LIFO stands for "Last-In, First-Out." It is a cache replacement policy where the most recently added entry in the cache is removed first when the cache reaches its maximum capacity.

What LRU means: LRU stands for "Least Recently Used." It is a cache replacement policy where the least recently accessed entry in the cache is removed first when the cache reaches its maximum capacity.

What MRU means: MRU stands for "Most Recently Used." It is a cache replacement policy where the most recently accessed entry in the cache is removed first when the cache reaches its maximum capacity.

What LFU means: LFU stands for "Least Frequently Used." It is a cache replacement policy where the least frequently accessed entry in the cache is removed first when the cache reaches its maximum capacity.

What the purpose of a caching system is: The purpose of a caching system is to improve performance by reducing the time it takes to access frequently used data. By storing this data closer to where it is needed, such as in faster memory or in a local cache, it can be retrieved more quickly, thus reducing latency and improving overall system efficiency.

What limits a caching system has: Caching systems have limits in terms of the amount of data they can store (cache capacity), the replacement policies they employ, and the algorithms used to manage the cache. These limits can affect the effectiveness and efficiency of the caching system in improving performance.